{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wec7pstak8Wg"
      },
      "source": [
        "## Working with the Brown Corpus (using nltk):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsNizpBuk8Wh"
      },
      "source": [
        "To get the Borwn corpus, do **either** this:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')"
      ],
      "metadata": {
        "id": "fbKGtIq2l-lF",
        "outputId": "493fe33d-6ea9-4226-fe8a-efb549b9ac15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ao7Og0Ijk8Wh"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5gN10cDk8Wh"
      },
      "source": [
        "of if that doesn't work, **this**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "j0a8tZE4k8Wh",
        "outputId": "50f42d92-f114-46d1-eb30-8918f1c85600"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'download' from 'nltk.corpus' (/usr/local/lib/python3.12/dist-packages/nltk/corpus/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3967974976.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"brown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'download' from 'nltk.corpus' (/usr/local/lib/python3.12/dist-packages/nltk/corpus/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from nltk.corpus import download\n",
        "download(\"brown\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDdGJDm9k8Wj"
      },
      "source": [
        "The following code cell assigns a list of all 1.2 M word tokens in `brown` to the name `bw`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kpiTKMcuk8Wj"
      },
      "outputs": [],
      "source": [
        "bw = brown.words()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29ocircOk8Wk"
      },
      "source": [
        "The value of the name `bw`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuXnCEbOk8Wk",
        "outputId": "032850ba-3a91-4faf-f991-e56d2d9a8afa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "bw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxpLsSV-k8Wl"
      },
      "source": [
        "To get a data structure with all the word counts, do:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WPheKJJZk8Wl"
      },
      "outputs": [],
      "source": [
        "fd = nltk.FreqDist(bw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of9VRGnQk8Wm"
      },
      "source": [
        "What `fd` is is an`nltk FreqDist` (Frequency Distribution), essentially, a Python dictionary containing the count of all the word types in Brown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX_a6qAtk8Wm",
        "outputId": "800b64b2-c45d-4ab4-e7e4-bb9754a05f07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "fd[\"computer\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MZIA_cnk8Wm"
      },
      "source": [
        "That means there are 13 *tokens* of the word type 'computer' in the Brown corpus.  Note that case matters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdLGD6itk8Wm",
        "outputId": "34ce753b-b2b0-4f8c-c703-a86a990b607b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "fd[\"Computer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKEjiOgyk8Wm",
        "outputId": "b118447d-6aaa-41cb-b230-82d05da9e337"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62713, 7258)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "fd['the'],fd['The']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-rdKRwbk8Wn"
      },
      "source": [
        "The `fd` FreqDist also has some features customized for word frequencies, like the `most_common` method), which allows you to find the top n most frequent words and their counts. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8uMsaVEk8Wn",
        "outputId": "30eb41dc-3fe3-4986-8c29-f1fbe1b28e64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 62713), (',', 58334), ('.', 49346)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "fd.most_common(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXSqDrVok8Wn"
      },
      "source": [
        "To find the number of word tokens in Brown, find the length of `bw`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNd2v3W3k8Wn",
        "outputId": "1531dcfd-44a5-4d22-9dab-c50e2888302e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1161192"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(bw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_NCgpRUk8Wn"
      },
      "source": [
        "So, about 1.16 Million words.  You can also do this more efficiently, by using another one of the customized methods provided by a `FreqDist`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PefzXd8k8Wo",
        "outputId": "ad124805-e6ed-43c6-e68a-6dd6e149521b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1161192"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "fd.N()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwuVirSak8Wo"
      },
      "source": [
        "To find out the number of **word types** in Brown, just get the length of the `fd` dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlMIrxp3k8Wo",
        "outputId": "65a62177-fe95-4988-9a93-7f3a06ef503d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56057"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(fd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlTixMuKk8Wo"
      },
      "source": [
        "It is handy to ignore case for purposes of this exercise. To do that, just lowercase all the words in Brown before making the frequency distribution. This changes the number of word types, but not the number of word tokens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSdJ3X0Vk8Wo",
        "outputId": "a5d265d3-6520-48d3-abca-0e2b9d20e711"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1161192"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# This uses what Pythonistas call a list comprehension.\n",
        "# It's just a compact way of writing a loop and collecting results in  a list.\n",
        "bw = brown.words()\n",
        "bw = [w.lower() for w in bw]\n",
        "len(bw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMXOtobjk8Wo"
      },
      "source": [
        "The length of the **corpus** (the body of data) hasn't changed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOjIU1_sk8Wp",
        "outputId": "47e3769c-94ad-4140-85e6-4957979aaaeb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49815"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "fd = nltk.FreqDist(bw)\n",
        "len(fd)\n",
        "#49815"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_XAFOfyk8Wp"
      },
      "source": [
        "The dictionary has shrunk because we now ignore the distinction between 'The' and 'the'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RatEAoZWk8Wp",
        "outputId": "d4740856-24b9-4da2-b7c5-2a3a4c3f9ef8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69971"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "fd['the']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23PzyGq4k8Wp",
        "outputId": "d9b1a132-c80d-4834-907b-d087989a25fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "fd['The']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnvbxK6Bk8Wp"
      },
      "source": [
        "You may find it useful to take a look at [Chapter One of the NLTK book.](http://www.nltk.org/book/ch01.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EL6pWoNk8Wp"
      },
      "source": [
        "### Constructing a bigram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "IzE5ETPSk8Wp"
      },
      "outputs": [],
      "source": [
        "# The Brown Corpus\n",
        "from nltk.corpus import brown\n",
        "from nltk import FreqDist\n",
        "from nltk import bigrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL6qJhiSk8Wp"
      },
      "source": [
        "Here is some helpful code for computing the counts in the **Brown Corpus** needed for a bigram model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "x4a_ifLSk8Wp"
      },
      "outputs": [],
      "source": [
        "#Lowers case all the words\n",
        "words = [w.lower() for w in brown.words()]\n",
        "fd = FreqDist(words)\n",
        "fd2 = FreqDist(bigrams(words))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_ct = fd[\"of\"]\n",
        "bigram_ct = fd2[(\"of\",\"the\")]\n",
        "p_the_given_of = bigram_ct / unigram_ct\n",
        "unigram_ct, bigram_ct, p_the_given_of\n"
      ],
      "metadata": {
        "id": "cSUH7U2KnkHB",
        "outputId": "5bce60bd-0d1b-4da7-8a95-cc197434ce68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36412, 9717, 0.26686257277820497)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_ct_2 = fd2[(\"football\",\"player\")]\n",
        "unigram_ct_2 = fd[\"football\"]\n",
        "p_player_given_football = bigram_ct_2 / unigram_ct_2\n",
        "\n",
        "total_bigrams = fd2.N()\n",
        "p_football_player = bigram_ct_2 / total_bigrams\n",
        "\n",
        "bigram_ct_2, unigram_ct_2, p_player_given_football, total_bigrams, p_football_player"
      ],
      "metadata": {
        "id": "51N8Iydynp9y",
        "outputId": "6f1017c7-53e3-4cb8-faeb-c62f43ebbb4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 36, 0.027777777777777776, 1161191, 8.611847663304314e-07)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_1 = fd[\"football\"]\n",
        "count_2 = fd.N()\n",
        "count_1, count_2, count_1 / count_2\n"
      ],
      "metadata": {
        "id": "rbAetNK0nuXK",
        "outputId": "aab4a34f-baf8-46f8-9eaf-590e79b0de17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 1161192, 3.100262488890726e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "of_follow_counts = Counter()\n",
        "for (w1, w2), ct in fd2.items():\n",
        "    if w1 == \"of\":\n",
        "        of_follow_counts[w2] += ct\n",
        "\n",
        "top20 = sorted(of_follow_counts.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "\n",
        "total_of_ct = fd[\"of\"]\n",
        "sum_of_cts_of_top_20_of_followers = sum(ct for _, ct in top20)\n",
        "top_20_of_followers = sum_of_cts_of_top_20_of_followers / total_of_ct\n",
        "\n",
        "total_of_ct, sum_of_cts_of_top_20_of_followers, top_20_of_followers\n"
      ],
      "metadata": {
        "id": "U7yx8TT7nyad",
        "outputId": "8d0ddbb6-a835-40d3-e867-ab57c4cd4689",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36412, 16122, 0.44276612105899155)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import trigrams\n",
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "punct = set(string.punctuation)\n",
        "\n",
        "def ok(tok):\n",
        "    return tok != \"of\" and tok not in punct\n",
        "\n",
        "tri_counts = Counter(\n",
        "    t for t in trigrams(words)\n",
        "    if all(ok(w) for w in t)\n",
        ")\n",
        "\n",
        "most_common_lexical_trigram = tri_counts.most_common(1)[0][0]\n",
        "most_common_lexical_trigram\n"
      ],
      "metadata": {
        "id": "a4Rw6GCMnzXN",
        "outputId": "1751e90b-d097-44b0-af97-bf67aa3032d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('the', 'united', 'states')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-6jW7Ndyn173"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvVLzShJk8Wp"
      },
      "source": [
        "Number of times the word *bald* appeared in the Brown corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TzHmLVyk8Wp",
        "outputId": "e5171a89-9110-4b7f-a5c0-02ff0c4e4bf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "fd[\"bald\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGYzJwrck8Wp"
      },
      "source": [
        "Number of times the bigram *stormy weather* appeared in  the Brown corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o8-HPMqk8Wv",
        "outputId": "2c8cc133-e6c0-46ab-b792-72722adbc283"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "fd2[\"stormy\",\"weather\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap577Pank8Wv"
      },
      "source": [
        "Total count of the word tokens in the Brown corpus is unchanged:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CM3TXspk8Wv",
        "outputId": "9090e6c7-e109-4046-f464-d681eff93493"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1161192"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "fd.N()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxpnuisKk8Ww"
      },
      "source": [
        "Total count of all the bigram tokens in the Brown corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6lxZcnVk8Ww",
        "outputId": "676a7570-2c0e-4ff0-9020-89a6440f806c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1161191"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "fd2.N()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h1KPADSk8Ww"
      },
      "source": [
        "Twenty most common words in the Brown corpus together with their counts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzjRU73Bk8Ww",
        "outputId": "87944f53-e1c0-436d-bd6c-24b5c7967391"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 69971),\n",
              " (',', 58334),\n",
              " ('.', 49346),\n",
              " ('of', 36412),\n",
              " ('and', 28853),\n",
              " ('to', 26158),\n",
              " ('a', 23195),\n",
              " ('in', 21337),\n",
              " ('that', 10594),\n",
              " ('is', 10109),\n",
              " ('was', 9815),\n",
              " ('he', 9548),\n",
              " ('for', 9489),\n",
              " ('``', 8837),\n",
              " (\"''\", 8789),\n",
              " ('it', 8760),\n",
              " ('with', 7289),\n",
              " ('as', 7253),\n",
              " ('his', 6996),\n",
              " ('on', 6741)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "fd.most_common(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or7E1s4ck8Ww"
      },
      "source": [
        "Twenty most common bigrams in the corpus together with their counts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40POJe2Vk8Ww",
        "outputId": "ffb1432e-815a-40ad-f63e-5e13220a59a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('of', 'the'), 9717),\n",
              " ((',', 'and'), 6302),\n",
              " (('.', 'the'), 6081),\n",
              " (('in', 'the'), 6025),\n",
              " ((',', 'the'), 3787),\n",
              " (('.', '``'), 3515),\n",
              " (('to', 'the'), 3484),\n",
              " ((\"''\", '.'), 3332),\n",
              " ((';', ';'), 2784),\n",
              " (('.', 'he'), 2660),\n",
              " (('on', 'the'), 2466),\n",
              " (('?', '?'), 2346),\n",
              " (('and', 'the'), 2246),\n",
              " ((\"''\", ','), 2032),\n",
              " ((',', 'but'), 1856),\n",
              " (('for', 'the'), 1852),\n",
              " (('.', 'it'), 1836),\n",
              " (('to', 'be'), 1718),\n",
              " (('at', 'the'), 1655),\n",
              " (('.', 'in'), 1619)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "fd2.most_common(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "21Id8Dmlk8Ww"
      },
      "outputs": [],
      "source": [
        "def restrict_most_common (fd,f_rest):\n",
        "    \"\"\"\n",
        "    Returns the x that satisfy restriction f_rest in sorted order\n",
        "    according to fd.most_common()\n",
        "    \"\"\"\n",
        "    bs,cts = zip(*[(x,ct) for (x,ct) in fd.most_common() if f_rest(x)])\n",
        "    return bs, np.array(cts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMIjl17Pk8Wx"
      },
      "source": [
        "Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "ahHbuvlSk8Wx",
        "outputId": "e673064f-0e3b-4bf4-e012-9ff3f8f19bcb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3598366684.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestrict_most_common\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m  \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grou\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3016145044.py\u001b[0m in \u001b[0;36mrestrict_most_common\u001b[0;34m(fd, f_rest)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[1;32m      6\u001b[0m     \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf_rest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "bs,cts = restrict_most_common (fd, lambda  x:x.startswith(\"grou\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYetJOGLk8Wx",
        "outputId": "40a91260-7800-4758-b4d9-a6f53d298384"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('group',\n",
              " 'ground',\n",
              " 'groups',\n",
              " 'grounds',\n",
              " 'groupings',\n",
              " 'grounded',\n",
              " 'groundwave',\n",
              " 'grouped',\n",
              " 'grouping',\n",
              " 'groundwork',\n",
              " 'grounding',\n",
              " 'grounder',\n",
              " \"group's\",\n",
              " 'groundless',\n",
              " 'ground-glass',\n",
              " 'ground-swell',\n",
              " 'ground-level',\n",
              " 'ground-truck')"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37grLj6Rk8Wx",
        "outputId": "d73bce00-db64-4ec2-ef87-7efde11867e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([390, 186, 125,  58,   9,   6,   6,   5,   4,   3,   2,   1,   1,\n",
              "         1,   1,   1,   1,   1])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cts"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}